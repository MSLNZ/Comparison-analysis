{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates success rates for all methods aside from BMA\n",
    "\n",
    "# Generates a specified number of test sets each with 12 participants with uncertainty and error determined from specified \n",
    "# distribution, and determines the proportion of the labs which fail each test.\n",
    "\n",
    "# Can update the participants function to generate success rates for different combinations of biased and unbiased\n",
    "# participants. See txt file in same folder as this to find other versions of the 'participants' function.\n",
    "\n",
    "code_version = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run methods notebook which contains functions for each of the methods used\n",
    "%run \"Methods-success-new-GTC.ipynb\" -G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two biased - can set to be ++ or +- by adjusting the sign.\n",
    "\n",
    "def participants(N,f,g,d):\n",
    "    # Generate a participant set, run the methods and return the required variables to determine success\n",
    "    # Takes in: N = number of participants\n",
    "    #           f = uncertainty of the biased lab\n",
    "    #           g = size of bias\n",
    "    #           d = degrees of freedom of Chi Square distribution used to generated uncertainties\n",
    "    # Returns:  y = uncertain array containing N participants, the first of which has a bias defined by f,g\n",
    "    \n",
    "    unc = np.array([np.random.chisquare(d)/d for i in range(0,N-2)])\n",
    "    unc = np.insert(unc, 0, f) # Set the first lab to have f=1\n",
    "    unc = np.insert(unc, 0, f) # Set the first lab to have f=1\n",
    "\n",
    "    # Generate errors from a Normal (0,unc) distribution\n",
    "    err = np.array([random.normalvariate(0,unc[i]) for i in range(2,N)])\n",
    "    err = np.insert(err, 0, [random.normalvariate(0,unc[1])+g]) # Set the first lab to have a bias of 6*unc\n",
    "    err = np.insert(err, 0, [random.normalvariate(0,unc[0])+g]) # Set the first lab to have a bias of 6*unc\n",
    "\n",
    "    # Put 12 participants into an uncertain number array\n",
    "    y = la.uarray([ureal(err[i],unc[i]) for i in range(0,N)])\n",
    "    \n",
    "    n_biased = 2\n",
    "    \n",
    "    return(y, n_biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_methods(y,N,d,u_d):\n",
    "    # Run the data through all the different methods\n",
    "    # Takes in: y = an uncertain array containing the data and uncertainties\n",
    "    #           N = the number of participants\n",
    "    #           d = matrix to store the differences\n",
    "    # Returns:  d = matrix containing all the differences\n",
    "    #           w_LCS = array showing which labs have been excluded in LCS\n",
    "    #           t = size of the largest coherent subset minus one, used as subset size in BMA\n",
    "    \n",
    "    # No cut with and without OO, MP\n",
    "    (d[0:], u_d[0:]) = NoCut(y,N,True,True)\n",
    "    (d[1:], u_d[1:]) = NoCut(y,N,True,False)\n",
    "    (d[2:], u_d[2:]) = NoCut(y,N,False,True)\n",
    "    (d[3:], u_d[3:]) = NoCut(y,N,False,False)\n",
    "\n",
    "    # Cut with and without OO, MP\n",
    "    (d[4:], u_d[4:]) = Cut(y,N,True,True)\n",
    "    (d[5:], u_d[5:]) = Cut(y,N,True,False)\n",
    "    (d[6:], u_d[6:]) = Cut(y,N,False,True)\n",
    "    (d[7:], u_d[7:]) = Cut(y,N,False,False)\n",
    "\n",
    "#     # LChS, BMA, LCS\n",
    "#     lchs = LChS(y,N)\n",
    "    t = 0\n",
    "\n",
    "#     d[8:] = BMA(y,N,t)\n",
    "    (d[8:], u_d[8:]) = LCS(y,N)\n",
    "\n",
    "    return(d,t,u_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def success(d,u_d,fail):\n",
    "    # Determine if each method fails, and if it does update the matrix fail. If the biased lab fails, update the array \n",
    "    # bias_fail.\n",
    "    # Takes in: d = matrix containing all the differences\n",
    "    #           w_LCS = array showing which labs have been excluded in LCS\n",
    "    #           fail = array in which to store the number of labs which fail\n",
    "    # Returns: fail = array containing the number of labs which failed using each method.\n",
    "    \n",
    "    temp = abs(d) > 1.96*u_d    \n",
    "    fail[:,] += temp\n",
    "\n",
    "    return(fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(T,N,f,g,df):\n",
    "    # Generate datasets, and tests them to see how many labs fail using each method\n",
    "    # Takes in: T = number of trials\n",
    "    #           N = number of participants\n",
    "    #           f = uncertainty of biased lab\n",
    "    #           g = size of bias\n",
    "    #           d = degrees of freedom used to generate biased labs\n",
    "    # Returns:  fail_rate = matrix containing the failure rates of each lab\n",
    "    #           t_ave_final = average subset size fed into BMA\n",
    "    \n",
    "    \n",
    "    # Create array in which to store the failure rates, and differences\n",
    "    fail = np.zeros((9,N))\n",
    "    d = la.uarray(np.zeros((9,N)),np.zeros((9,N)))\n",
    "    u_d = la.uarray(np.zeros((9,N)),np.zeros((9,N)))\n",
    "    \n",
    "    # Initialise stop (to break out of while loop), t_ave\n",
    "    stop = T * 1.\n",
    "    t_ave = 0\n",
    "\n",
    "    while stop > 0:\n",
    "        # Create participants\n",
    "        [y, n_biased] = participants(N,f,g,df)       \n",
    "        \n",
    "        # Run participant set through all the different methods\n",
    "        (d,t,u_d) = run_methods(y,N,d,u_d)\n",
    "        \n",
    "        # Update t_ave\n",
    "        t_ave += t\n",
    "        \n",
    "        # Calculate the failure rates and update fail\n",
    "        fail = success(d,u_d,fail)\n",
    "        \n",
    "        # Update stop, t_ave\n",
    "        stop -= 1\n",
    "    \n",
    "    # Calculate fail rates by dividing the number of labs which failed by the number of trials\n",
    "    fail_rate = fail/T\n",
    "    t_ave_final = t_ave/T\n",
    "    \n",
    "    return(fail_rate, t_ave_final, n_biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 12\n",
    "T = 1\n",
    "df = 4\n",
    "m = 5\n",
    "\n",
    "f_all = [0.25]\n",
    "g_all = [0.09375]\n",
    "\n",
    "for f in f_all:\n",
    "    for g in g_all:\n",
    "\n",
    "        # Initliase spreadsheet to save results\n",
    "        wb = xlwt.Workbook()\n",
    "        ws = wb.add_sheet('Fail rate')\n",
    "\n",
    "        # Generate failure rates\n",
    "        fail_rates, t, n_biased = simulate_data(T,N,f,g,df)\n",
    "        \n",
    "        if n_biased == 1:\n",
    "            ws.write(1,0,'Biased')\n",
    "        elif n_biased == 2:\n",
    "            ws.write(2,0,'Biased')\n",
    "            ws.write(3,0,'Biased')\n",
    "     \n",
    "        ws.write(0,1,'No cut (OO,MP)')\n",
    "        ws.write(0,2,'No cut (OO)')\n",
    "        ws.write(0,3,'No cut (MP)')\n",
    "        ws.write(0,4,'No cut')\n",
    "        ws.write(0,5,'Cut (OO,MP)')\n",
    "        ws.write(0,6,'Cut (OO)')\n",
    "        ws.write(0,7,'Cut (MP)')\n",
    "        ws.write(0,8,'Cut')\n",
    "        ws.write(0,9,'LCS')\n",
    "        \n",
    "        ws.write(0,11,'Version ' + str(code_version))\n",
    "\n",
    "        # Write results to spreadsheet\n",
    "        for i in range(0,N):\n",
    "            for j in range(0,9):\n",
    "                ws.write(i+1,j+1,fail_rates[j,i])\n",
    "\n",
    "        wb.save('two_bias+-,f='+str(f)+',g='+str(g)+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as methods-success, but works with the new numpy GTC\n",
    "\n",
    "# Code which is called by most files which generate success rates (up to date)\n",
    "\n",
    "# Rewriting methods-success to use GTC with arrays, and get rid of all the list comprehensions and remove the variable S\n",
    "\n",

    code_version = 1
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GTC import *\n",
    "import xlrd\n",
    "import math\n",
    "import xlwt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import operator as op\n",
    "import itertools\n",
    "import random\n",
    "from scipy.stats import chi2\n",
    "import xlsxwriter\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import rc, font_manager\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MP(y,theta,d,ChiSq,ChiEx,w_cs,N):\n",
    "    # Mandel-Paule\n",
    "\n",
    "    d_MP = d*1.   \n",
    "    U_adjust = 0\n",
    "    theta_MP = theta*1.\n",
    "    \n",
    "    if ChiSq > ChiEx+0.02:\n",
    "    \n",
    "        nsteps = 0\n",
    "        nsteps2 = 0\n",
    "\n",
    "        ChiDiff_Orig = ChiSq - ChiEx\n",
    "        ChiDiff =  ChiSq - ChiEx\n",
    "        U_adjust = ChiDiff*uncertainty(y[0])/1000.\n",
    "            \n",
    "        # Continue iteration until get chisq within 0.01 of target\n",
    "        while abs(ChiDiff) > 0.01 and nsteps2 < 10:\n",
    "            if nsteps > 500:\n",
    "                U_adjust = U_adjust*10.\n",
    "                nsteps = 0\n",
    "\n",
    "            nsteps += 1\n",
    "            nsteps2 += 1    \n",
    "\n",
    "    \n",
    "            # Add adjustment and recalculate weights, artefact values, DOEs and chisq.\n",
    "            y_MP = la.uarray([ureal(value(y[i]),uncertainty(y[i])+U_adjust) for i in range(0,N)])\n",
    "\n",
    "            wp = w_cs/(y_MP.uncertainty()**2)        \n",
    "            w_MP = wp/sum(wp)\n",
    "\n",
    "            theta_MP = np.dot(w_MP,y_MP)\n",
    "    \n",
    "            d_MP = y_MP - theta_MP\n",
    "                \n",
    "            ChiSq = np.array((np.sum(w_cs*np.array(d_MP.value())**2/(np.array(y_MP.uncertainty())**2))))\n",
    "            ChiDiff = ChiSq - ChiEx\n",
    "                \n",
    "            U_adjust = U_adjust*np.sqrt(abs(ChiDiff_Orig/(ChiDiff_Orig-ChiDiff)))\n",
    "        \n",
    "    return(theta_MP,d_MP,U_adjust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MP_C(y,theta,d,ChiSq,ChiEx,w_cs,N):\n",
    "    # Mandel-Paule with cut off\n",
    "    \n",
    "    d_MP = d*1.  \n",
    "    U_adjust = 0\n",
    "    theta_MP = theta*1.\n",
    "    w_MP = w_cs*1.\n",
    "\n",
    "    if ChiSq > ChiEx+0.02:\n",
    "    \n",
    "        nsteps = 0\n",
    "        nsteps2 = 0\n",
    "\n",
    "        ChiDiff_Orig = ChiSq - ChiEx\n",
    "        ChiDiff =  ChiSq - ChiEx\n",
    "        U_adjust = ChiDiff*uncertainty(y[0])/1000.\n",
    "            \n",
    "        # Continue iteration until get chisq within 0.01 of target\n",
    "        while abs(ChiDiff) > 0.01 and nsteps2 < 10:\n",
    "            if nsteps > 200:\n",
    "    \n",
    "                U_adjust = U_adjust*10.\n",
    "                nsteps = 0\n",
    "\n",
    "            nsteps += 1\n",
    "            nsteps2 += 1\n",
    "\n",
    "            # Add adjustment and recalculate weights, artefact values, DOEs and chisq.\n",
    "            y_MP = la.uarray([ureal(value(y[i]),uncertainty(y[i])+U_adjust) for i in range(0,N)])\n",
    "            \n",
    "            # Calculate weights with cutoff\n",
    "            u_vector = np.array(y_MP.uncertainty())\n",
    "            u_cut = np.zeros([N])\n",
    "            temp = np.sort(u_vector)\n",
    "            cut = np.mean(temp[0:round(N/2)])\n",
    "                \n",
    "            for i in range(0,N):\n",
    "                if u_vector[i] < cut:\n",
    "                    u_cut[i] = cut        \n",
    "                else:\n",
    "                    u_cut[i] = u_vector[i]\n",
    "                \n",
    "            wp = w_cs/(u_cut**2)\n",
    "            w_MP = wp/sum(wp)\n",
    "\n",
    "            theta_MP = np.dot(w_MP,y_MP)\n",
    "            d_MP = y_MP - theta_MP\n",
    "\n",
    "            # Recalculate ChiSq\n",
    "            ChiSq = np.sum(w_cs*np.array(d_MP.value())**2/(np.array(y_MP.uncertainty())**2))\n",
    "            ChiDiff = ChiSq - ChiEx\n",
    "                \n",
    "            U_adjust = U_adjust*np.sqrt(abs(ChiDiff_Orig/(ChiDiff_Orig-ChiDiff)))\n",
    "            \n",
    "    return(theta_MP,d_MP,U_adjust,w_MP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OO(y,theta,d,ChiSq,ChiEx,N):\n",
    "    # Obvious outliers\n",
    "    \n",
    "    # Calculate distance from theta\n",
    "    dist = d.value()/(6*d.uncertainty())\n",
    "    \n",
    "    # Initialise d_OO, theta_OO, ChiSq_OO\n",
    "    d_OO = d*1.\n",
    "    theta_OO = theta*1. \n",
    "    ChiSq_OO = ChiSq*1. \n",
    "    \n",
    "    # Weighting for model\n",
    "    w_cs = np.ones((N))\n",
    "\n",
    "    n = 0\n",
    "        \n",
    "    for i in range(0,N):\n",
    "        if abs(dist[i]) > 1.0:\n",
    "            # Set weighting for model to zero\n",
    "            w_cs[i] = 0.\n",
    "            n = n+1\n",
    "    \n",
    "    # If some weighting changes\n",
    "    if n > 0: \n",
    "        wp = w_cs/(y.uncertainty()**2)          \n",
    "        w_OO = wp/sum(wp)\n",
    "                \n",
    "        # Fundamental constant model y_i = theta + e_i\n",
    "        theta_OO = np.dot(w_OO,y)\n",
    "        d_OO = y-theta_OO\n",
    "                \n",
    "        # Recalculate chisq\n",
    "        chp = (w_cs*d_OO.value()**2)/(d_OO.uncertainty()**2)\n",
    "        ChiSq_OO = np.sum(np.array(chp.value())) \n",
    "\n",
    "                \n",
    "    return [theta_OO,d_OO,ChiSq_OO,w_cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OO_C(y,theta,d,ChiSq,ChiEx,N):\n",
    "    # Obvious outliers with cut off\n",
    "    \n",
    "    # Calculate distance from theta\n",
    "    dist = d.value()/(6*d.uncertainty())\n",
    "    \n",
    "    # Initialise d_OO, theta_OO, ChiSq_OO\n",
    "    d_OO = d*1.\n",
    "    theta_OO = theta*1.\n",
    "    ChiSq_OO = ChiSq*1.\n",
    "\n",
    "    # Weighting for model\n",
    "    w_cs = np.ones((N))\n",
    "    \n",
    "    n = 0\n",
    "    for i in range(0,N):\n",
    "        if abs(dist[i]) > 1.0:\n",
    "            # Set weighting for model to zero\n",
    "            w_cs[i] = 0.\n",
    "            n += 1\n",
    "        \n",
    "    if n > 0:\n",
    "        # Calculate weights with cutoff\n",
    "        u_vector = np.array(y.uncertainty())\n",
    "        u_cut = np.zeros([N])\n",
    "        temp = np.sort(u_vector)\n",
    "        cut = np.mean(temp[0:round(N/2)])\n",
    "                \n",
    "        for i in range(0,N):\n",
    "            if u_vector[i] < cut:\n",
    "                u_cut[i] = cut        \n",
    "            else:\n",
    "                u_cut[i] = u_vector[i]\n",
    "                \n",
    "        # Update weights\n",
    "        wp = w_cs/(u_cut**2)          \n",
    "        w_OO = wp/sum(wp)\n",
    "\n",
    "        # Fundamental constant model y_i = theta + e_i\n",
    "        theta_OO = np.dot(w_OO,y)\n",
    "        d_OO = y-theta_OO\n",
    "\n",
    "        # Recalculate chisq\n",
    "        chp = (w_cs*np.array(d_OO.value())**2)/(np.array(d_OO.uncertainty())**2)\n",
    "        ChiSq_OO = np.sum(chp)\n",
    "\n",
    "    return [theta_OO,d_OO,ChiSq_OO,w_cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoCut(y,N,apply_OO,apply_MP):\n",
    "    \n",
    "    # Calculate weights\n",
    "    wp = 1./(y.uncertainty()**2)          \n",
    "    w = wp/sum(wp) \n",
    "    \n",
    "    # Fundamental constant model y_i = theta + e_i\n",
    "    theta = np.dot(w,y)\n",
    "    d = y-theta\n",
    "\n",
    "    # Calculate chisq\n",
    "    chp = d.value()**2/(d.uncertainty()**2)\n",
    "    ChiSq = np.sum(np.array(chp.value()))\n",
    "    \n",
    "    ChiEx = chi2.isf(0.05,N-1)\n",
    "\n",
    "    if apply_OO == True:\n",
    "        # Check for 'obvious outliers' and recalculate \"if necc\n",
    "        [theta_OO,d_OO,ChiSq_OO,w_cs] = OO(y,theta,d,ChiSq,ChiEx,N)\n",
    "    else:\n",
    "        # Otherwise set theta_OO, d_OO, ChiSq_OO to the values without OO and w_cs as a vector of ones\n",
    "        theta_OO = theta*1.\n",
    "        d_OO = d*1.\n",
    "        ChiSq_OO = ChiSq*1.\n",
    "        w_cs = np.ones(N)\n",
    "    \n",
    "    if apply_MP == True:\n",
    "        # Check for consistency and apply MP if necc\n",
    "        [theta_MP,d_MP,U_adjust] = MP(y,theta_OO,d_OO,ChiSq_OO,ChiEx,w_cs,N)\n",
    "    else:\n",
    "        # Otherwise set theta_MP and d_MP to the values without MP\n",
    "        theta_MP = theta_OO*1.\n",
    "        d_MP = d_OO*1.\n",
    "    \n",
    "    d_MP1 = np.array(d_MP.value())\n",
    "    u_d = np.array(d_MP.uncertainty())\n",
    "\n",
    "    return(d_MP1, u_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cut(y,N,apply_OO,apply_MP):\n",
    "\n",
    "    # Weights without cutoff\n",
    "    u_vector = np.array(y.uncertainty())\n",
    "    wp = 1./(u_vector**2)\n",
    "    w0 = wp/sum(wp)\n",
    "    \n",
    "    # Calculate weights with cutoff\n",
    "    u_cut = np.zeros(N)\n",
    "    temp = np.array(np.sort(u_vector))\n",
    "    \n",
    "    # Find average of smallest half\n",
    "    cut = np.mean(temp[0:round(N/2)])\n",
    "\n",
    "    for i in range(0,N):\n",
    "        if u_vector[i] < cut:\n",
    "            u_cut[i] = cut       \n",
    "        else:\n",
    "            u_cut[i] = u_vector[i]\n",
    "    \n",
    "    wp = 1./(u_cut**2)          \n",
    "    w = wp/sum(wp) \n",
    "    \n",
    "    # Fundamental constant model y_i = theta + e_i\n",
    "    theta_C = np.dot(w,y)\n",
    "    d_C = y-theta_C\n",
    "    \n",
    "    # Calculate chisq\n",
    "    chp = np.array(d_C.value())**2/(np.array(d_C.uncertainty())**2)\n",
    "    ChiSq_C = np.sum(chp)\n",
    "    \n",
    "    ChiEx = chi2.isf(0.05,N-1)\n",
    "    \n",
    "    \n",
    "    if apply_OO == True:\n",
    "        # Check for 'obvious outliers' and recalculate \"if necc\n",
    "        [theta_OO_C,d_OO_C,ChiSq_OO_C,w_cs] = OO_C(y,theta_C,d_C,ChiSq_C,ChiEx,N)\n",
    "    else:\n",
    "        # Otherwise set theta_OO, d_OO, ChiSq_OO to the values without OO and w_cs as a vector of ones\n",
    "        theta_OO_C = theta_C*1.\n",
    "        d_OO_C = d_C*1.\n",
    "        ChiSq_OO_C = ChiSq_C*1.\n",
    "        w_cs = np.ones(N)\n",
    "    \n",
    "    if apply_MP == True:\n",
    "        # Check for consistency and apply MP if necc\n",
    "        [theta_MP_C,d_MP_C,U_adjust_C,w_MP_C] = MP_C(y,theta_OO_C,d_OO_C,ChiSq_OO_C,ChiEx,w_cs,N)\n",
    "    else:\n",
    "        # Otherwise set theta_MP and d_MP to the values without MP\n",
    "        theta_MP_C = theta_OO_C*1.\n",
    "        d_MP_C = d_OO_C*1.\n",
    "        \n",
    "    d_MP_C1 = np.array(d_MP_C.value())\n",
    "    u_d = np.array(d_MP_C.uncertainty())\n",
    "\n",
    "    return (d_MP_C1, u_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LChS(y,N):\n",
    "    # Largest coherent subset\n",
    "    # To store maximum subset size\n",
    "    lchs = [0,0]\n",
    "    \n",
    "    # Calculate the values of alpha_star and z\n",
    "    alpha_star = 2*(0.05/(N*(N-1)))\n",
    "    z = stats.norm.ppf(1-alpha_star/2)\n",
    "    \n",
    "    # Initialise I to store results. I will contain a 1 in the i,j th position if NMIs i,j are not equivalent, and a 0 if\n",
    "    # they are equivalent\n",
    "    I = np.ones(([N,N]))\n",
    "        \n",
    "    # Iterate through the NMIs twice\n",
    "    for i in range(0,N):\n",
    "        for k in range(0,N):  \n",
    "                \n",
    "            if i != k:\n",
    "                # If i,k correspond to different NMIs\n",
    "                    \n",
    "                # Calculate the lower and upper bounds to t\n",
    "                lower = value(y[i]) - value(y[k]) - z*np.sqrt(uncertainty(y[i])**2 + uncertainty(y[k])**2)\n",
    "                upper = value(y[i]) - value(y[k]) + z*np.sqrt(uncertainty(y[i])**2 + uncertainty(y[k])**2)\n",
    "                \n",
    "                # If lower < 0 < upper update I to show i,k are equivalent\n",
    "                if lower < 0 and upper > 0:\n",
    "                    I[i,k] = 0\n",
    "                \n",
    "            else:\n",
    "                # If we are considering the same NMI, then it is equivalent to itself so set I to 0\n",
    "                I[i,k] = 0\n",
    "    \n",
    "    \n",
    "    # Determine the largest coherent subset for each column\n",
    "    # Create dictionaries to store values, equiv for the NMIs which are equivalent pairwise\n",
    "    equiv = {}\n",
    "\n",
    "    for i in range(0,N):\n",
    "        # Iterate through the rows in the matrix\n",
    "        equiv[i] = []\n",
    "\n",
    "        for k in range(0,N):\n",
    "            # Iterate through the columns\n",
    "\n",
    "            if I[i][k]==0:\n",
    "                # If 0, add to a\n",
    "                equiv[i].append(k)\n",
    "        \n",
    "    lchs = 0 # to store maximum subset size\n",
    "        \n",
    "    for i in range(0,N):\n",
    "        # Iterate through the rows of the matrix\n",
    "        s = []\n",
    "        s.append(i)\n",
    "        rows = list(range(0,N))\n",
    "        stop = False\n",
    "    \n",
    "        while stop == False:\n",
    "            # Until we finish going through all rotations of the list\n",
    "                \n",
    "            # Iterate through the rows of the matrix and if the row is equivalent to all elements in s, add row j to s\n",
    "            for k in rows:\n",
    "                test = 0\n",
    "                for v in s:\n",
    "                    if k not in equiv[v]:\n",
    "                        test += 1\n",
    "                if test == 0:\n",
    "                    s.append(k)\n",
    "                \n",
    "            # Get rid of any repeats in s, and if its length is longer than the largest so far, save it\n",
    "            s2 = set(s)\n",
    "            if len(s2) >= lchs:\n",
    "                lchs = len(s2)\n",
    "        \n",
    "            # Move all the elements in the list rows around\n",
    "            rows = rows[1:] + [rows[0]]\n",
    "                \n",
    "            s = []\n",
    "            s.append(i)\n",
    "        \n",
    "            # If we have tried all possible starting elements, get out of loop\n",
    "            if rows[0] == 0:\n",
    "                stop = True  \n",
    "    \n",
    "    return(lchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BMA(y,N,t):\n",
    "    # Bayesian model averaging\n",
    "    import operator as op\n",
    "    import itertools\n",
    "    \n",
    "    S_N = set((i for i in range(0,N)))\n",
    "    \n",
    "    # List of all subsets of size t in set s of size N\n",
    "    ss = [set(i) for i in itertools.combinations(S_N, t)]\n",
    "    Q = len(ss)\n",
    "    \n",
    "    # Convert to array of arrays\n",
    "    St =np.array([list(ss[i]) for i in range(0,Q)])\n",
    "    \n",
    "    P_P = np.zeros([Q],dtype = object)\n",
    "    d_all = np.zeros([N,Q],dtype = object)\n",
    "    theta_all = np.zeros([Q],dtype = object)\n",
    "    alpha_all = np.zeros([N,Q],dtype = object)\n",
    "    var_mu_M = np.zeros([Q],dtype = float)\n",
    "    var_alpha_M = np.zeros([N,Q],dtype = float)\n",
    "    \n",
    "    for m in range(0,Q):\n",
    "        # Weighting vector for set of participants with zero bias\n",
    "        w_s = np.zeros([N,])\n",
    "        \n",
    "        for i in range(0,t):      \n",
    "            w_s[St[m,i]] = 1.   \n",
    "        \n",
    "        # Inverse uncerts for only non-zero participants\n",
    "        wa = np.array([(1-w_s[i])/(uncertainty(y[i])**2) for i in range(0,N)])\n",
    "        \n",
    "        # Inverse uncerts for zero-bias participants\n",
    "        wp = w_s/(y.uncertainty()**2)         \n",
    "        \n",
    "        # Weights for zero-bias participants\n",
    "        w = wp/sum(wp) \n",
    "        \n",
    "        # Equation 12\n",
    "        var_mu_M[m] = 1./sum(wp)\n",
    "        \n",
    "        # Fundamental constant model y_i = theta + e_i\n",
    "        theta_all[m] = var_mu_M[m]*np.dot(wp,y)\n",
    "        \n",
    "        # d is used to calculate probabilities\n",
    "        d_all[:,m] = y - theta_all[m]\n",
    "    \n",
    "        # But biases should be zero for the participants with zero bias\n",
    "        # Random variable alpha_i, Equation 13\n",
    "        alpha_all[:,m] = np.array([(1.-w_s[i])*(y[i]-theta_all[m]) for i in range(0,N)])\n",
    "        \n",
    "        # Variance of random variable alpha_i under model M_l, Equation 14\n",
    "        var_alpha_M[:,m] = np.array([(1.-w_s[i])*(uncertainty(y[i])**2+var_mu_M[m]) for i in range(0,N)])\n",
    "        \n",
    "        # Equation 6\n",
    "        P1_e = np.array([exp(-d_all[i,m]**2*wp[i]/2.) for i in range(0,N)])\n",
    "        P1 = np.product(P1_e)\n",
    "        P2 = np.sqrt(var_mu_M[m])  \n",
    "        P3 = np.sqrt(np.product(np.compress(wp.flat!=0, wp.flat)))\n",
    "        \n",
    "        # Proportional probability of each model\n",
    "        P_P[m] = P1*P2*P3\n",
    "    \n",
    "    # Probability from Equation 6\n",
    "    S_P = np.sum(P_P)\n",
    "    P = np.array([P_P[m]/S_P for m in range(0,Q)])\n",
    "    \n",
    "    # Equation 8\n",
    "    alpha = np.array([(np.sum(alpha_all[i]*P)) for i in range(0,N)])\n",
    "    \n",
    "    # Equation 7\n",
    "    mu = np.sum(theta_all*P)\n",
    "    \n",
    "    # Equation 10\n",
    "    v_a=np.array([[(var_alpha_M[i,m]+(value(alpha_all[i,m])-value(alpha[i]))**2)*P[m] for i in range(0,N)]for m in range(0,Q)])\n",
    "\n",
    "    # Equation 9\n",
    "    v_m = np.array([(var_mu_M[m]+(value(theta_all[m])-value(mu))**2)*P[m] for m in range(0,Q)])\n",
    "    \n",
    "    unc_alpha = np.array([np.sqrt(value(np.sum(v_a[:,i]))) for i in range(0,N)])\n",
    "    unc_mu = np.sqrt(value((np.sum(v_m))))\n",
    "    \n",
    "    # Put alpha, unc_alpha into an uncertain array\n",
    "    alpha_f = la.uarray([ureal(value(alpha[i]),value(unc_alpha[i])) for i in range(0,len(alpha))])   \n",
    "    \n",
    "    return(alpha_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS(y,N):\n",
    "    # Largest consistent subset\n",
    "    S_N = set((i for i in range(0,N)))\n",
    "    w_set=np.zeros([N], dtype = int)\n",
    "    d=np.empty([N],dtype = object)\n",
    "    \n",
    "    NotDone = 0\n",
    "\n",
    "    t = N*1\n",
    "    NotDone = 0\n",
    "    while NotDone==0:\n",
    "        # List of all subsets of size t in set s of size N\n",
    "        ss = [set(i) for i in itertools.combinations(S_N, t)]\n",
    "        \n",
    "        # Convert to array of arrays\n",
    "        St =np.array([list(ss[i]) for i in range(0,len(ss))])\n",
    "        Q = len(ss)\n",
    "            \n",
    "        d_all = np.zeros([N,Q],dtype = object)\n",
    "        theta_all = np.zeros([Q],dtype = object)\n",
    "        chp = np.zeros([N,Q],dtype = float)\n",
    "        ChiSq_all = np.zeros([Q],dtype = float)\n",
    "        w_s = np.zeros([N,Q],dtype = int)\n",
    "    \n",
    "        for m in range(0,Q):\n",
    "            # Weighting vector for set of participants with zero bias\n",
    "            for i in range(0,t):      \n",
    "                w_s[St[m,i],m] = 1. \n",
    "\n",
    "            # Calculate weights taking into account missing participants for this subset\n",
    "            wp = np.array([w_s[i,m]/(uncertainty(y[i])**2)  for i in range(0,N)])          \n",
    "            w = wp/sum(wp)\n",
    "\n",
    "            # Fundamental constant model y_i = theta + e_i\n",
    "            theta_all[m] = np.dot(w,y) \n",
    "\n",
    "            # d\n",
    "            d_all[:,m] = y - theta_all[m]\n",
    "\n",
    "            # Calculate chisq\n",
    "            chp[:,m] = np.array([w_s[i,m]*value(d_all[i,m])**2/(uncertainty(d_all[i,m])**2) for i in range(0,N)])\n",
    "            ChiSq_all[m] = np.sum(chp[:,m])            \n",
    "                \n",
    "        if min(ChiSq_all)>chi2.isf(0.05,t-1):\n",
    "            t = t-1\n",
    "        else:\n",
    "            NotDone = 1\n",
    "            \n",
    "    set_index = np.argmin(ChiSq_all)\n",
    "\n",
    "    w_set = w_s[:,set_index]\n",
    "    ChiSq = ChiSq_all[set_index]\n",
    "\n",
    "    d = la.uarray(d_all[:,set_index])\n",
    "    theta = theta_all[set_index]\n",
    "    \n",
    "    d1 = np.array(d.value())\n",
    "    u_d = np.array(d.uncertainty())\n",
    "                \n",
    "    return(d1, u_d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

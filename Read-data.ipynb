{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from excel file. Excel file needs to be in the right format. Can then use the data to apply either the first or\n",
    "# second model.\n",
    "\n",
    "# First sheet contains the number of participants, artefacts, and measurements as well as a table showing which participants\n",
    "# measured which artefacts, and details of the linking. The second sheet has a column of the measurement values, and the \n",
    "# covariance matrix. Contents of other sheets don't matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import math\n",
    "import xlwt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import numpy.linalg as linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    # Takes in filename and gets data about the comparison\n",
    "    # Calculates the design matrix, and stores the measurement values and the covariance matrix\n",
    "    \n",
    "    # Open workbook\n",
    "    book = xlrd.open_workbook(filename)\n",
    "    sheet1 = book.sheet_by_index(0)\n",
    "    \n",
    "    # Get information about comparison (Number of artefacts (F), participants (P), measurements (N))\n",
    "    NumArtefacts = int(sheet1.cell_value(2,1))\n",
    "    NumParticipants = int(sheet1.cell_value(3,1))\n",
    "    NumMeasurements = int(sheet1.cell_value(4,1))\n",
    "\n",
    "    # Save artefact and participant names\n",
    "    ArtefactNames = []\n",
    "    for i in range(0,NumArtefacts):\n",
    "        ArtefactNames.append(sheet1.cell_value(8,i+1))\n",
    "\n",
    "    ParticipantNames = []\n",
    "    for i in range(0,NumParticipants):\n",
    "        ParticipantNames.append(sheet1.cell_value(i+9,0))\n",
    "\n",
    "    # Get the measurements (y) and covariance matrix (U) from the comparison, y is the list of measurements, and U is the \n",
    "    # covariance matrix (uncertainties squared, with correlations on the off diagonal)\n",
    "    sheet2 = book.sheet_by_index(1)\n",
    "    y = np.zeros((NumMeasurements,1))\n",
    "    U = np.zeros((NumMeasurements, NumMeasurements))\n",
    "    \n",
    "    for i in range(0,NumMeasurements):\n",
    "        y[i,0] = sheet2.cell_value(i+3,1)\n",
    "    \n",
    "        for j in range(0,NumMeasurements):\n",
    "            U[i,j] = sheet2.cell_value(i+3,j+7)\n",
    "\n",
    "    # Save the measurement titles\n",
    "    MeasurementTitles = []\n",
    "    for i in range(0,NumMeasurements):\n",
    "        MeasurementTitles.append([sheet2.cell_value(i+3,2)])\n",
    "        MeasurementTitles[i].append(sheet2.cell_value(i+3,3))\n",
    "        MeasurementTitles[i].append(sheet2.cell_value(i+3,4))\n",
    "    \n",
    "    # Create the matrix X, and calculate the weights. w is the list of weights, and X is the design matrix\n",
    "\n",
    "    # Initialise matrix to store X\n",
    "    X = np.zeros((NumMeasurements, NumArtefacts + NumParticipants))\n",
    "\n",
    "    # Create vectors to store the average uncertainty for each NMI (used to determine the weights)\n",
    "    ave_U = np.zeros(NumParticipants)\n",
    "    count_per_lab = np.zeros(NumParticipants)\n",
    "\n",
    "    # Fill in 1's in the appropriate places in X\n",
    "    # Iterate through the number of measurements\n",
    "    for i in range(0, NumMeasurements):\n",
    "        \n",
    "        # Iterate through the number of artefacts\n",
    "        for j in range(0, NumArtefacts):\n",
    "            if MeasurementTitles[i][1] == ArtefactNames[j]:\n",
    "                X[i,j] = 1.0\n",
    "\n",
    "        # Iterate through the number of participants\n",
    "        for k in range(0, NumParticipants):\n",
    "            if MeasurementTitles[i][0] == ParticipantNames[k]:\n",
    "                X[i,NumArtefacts+k] = 1.0\n",
    "\n",
    "                # Add the uncertainty to the sum of uncertainties for lab k\n",
    "                ave_U[k] += np.sqrt(U[i,i]) \n",
    "                count_per_lab[k] += 1\n",
    "\n",
    "    # Determine the average uncertainty for each NMI by dividing the sum of their uncertainties by the number of measurements \n",
    "    # by that participant\n",
    "    ave_U = ave_U / count_per_lab\n",
    "    \n",
    "    # Initialise w to store the weights. The weight vector has length F+P, where the first F rows of w are all 0's, and the \n",
    "    # next P rows are the weights for each participant\n",
    "    w = np.zeros((NumArtefacts + NumParticipants, 1))\n",
    "\n",
    "    # Update the non-zero entries of w\n",
    "    for i in range(0, NumParticipants):\n",
    "        w[NumArtefacts+i, 0] = 1/(ave_U[i]**2)\n",
    "\n",
    "    # Standardise the weights so they sum to 1\n",
    "    w = w/sum(w)\n",
    "    \n",
    "    # Scale the weights so that they have the same order of magnitude as (X.T, inv(U), X) for when we use GLS\n",
    "    c = np.mean(linalg.multi_dot([X.T,linalg.inv(U),X]))/np.mean(np.dot(w,w.T))\n",
    "    w = np.sqrt(c)*w\n",
    "    \n",
    "    return(y, U, NumArtefacts, NumMeasurements, NumParticipants, ave_U, X, w,ParticipantNames,MeasurementTitles,count_per_lab,\n",
    "          ArtefactNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_beta(y, U, X, w):\n",
    "    # Calculates gamma, beta, CovBeta, ChiSq using GLS\n",
    "    # Takes in: measurements (y), covariance matrix (U), design matrix (X), weights (w)\n",
    "    # Returns:  gamma, beta, CovBeta\n",
    "    \n",
    "    gamma = np.linalg.multi_dot([ linalg.inv( np.linalg.multi_dot([X.T,linalg.inv(U),X]) + np.dot(w,w.T)), X.T, linalg.inv(U)])\n",
    "    beta = np.dot(gamma,y)\n",
    "    CovBeta = np.linalg.multi_dot([ gamma, U, gamma.T])\n",
    "    \n",
    "    return(gamma, beta, CovBeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_B(y, U, X, beta):\n",
    "    # Model B - calculates ChiSq using Model B and GLS\n",
    "    # y = theta + delta + e\n",
    "    # Takes in: measurements (y), covariance matrix (U), design matrix (X), beta\n",
    "    # Returns:  ChiSq calculated using Model B\n",
    "    \n",
    "    # Calculate ChiSq\n",
    "    ChiSq_B = np.linalg.multi_dot([ (y - np.dot(X, beta)).T, linalg.inv(U), (y - np.dot(X, beta))])\n",
    "    \n",
    "    return(ChiSq_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_A(beta, ave_U):\n",
    "    # Calculate ChiSq using model A and GLS\n",
    "    # Takes in: beta, average uncertainty for each lab\n",
    "    # Returns: ChiSq calculated using model A\n",
    "    \n",
    "    # Create a matrix cov_beta_diag which contains the diagonal elements of CovBeta, and zeros elsewhere\n",
    "    unc_diag = np.diag(ave_U**2)\n",
    "    \n",
    "    ChiSq_A = linalg.multi_dot([(beta[NumArtefacts:]).T, linalg.inv(unc_diag), beta[NumArtefacts:]])\n",
    "    \n",
    "    return(ChiSq_A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
